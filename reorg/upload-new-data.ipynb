{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove unused functions from library / combine/separate libraries into better modules\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import arrow\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import IPython.html.widgets as widgets\n",
    "\n",
    "from toolz import \\\n",
    "    partition,\\\n",
    "    thread_last,\\\n",
    "    thread_first\n",
    "    \n",
    "from utils import \\\n",
    "    snd,\\\n",
    "    exists_at_path,\\\n",
    "    get_layout_data,\\\n",
    "    add_dict_to_dataframe,\\\n",
    "    add_col,\\\n",
    "    maprows,\\\n",
    "    format_num\n",
    "    \n",
    "from IPython.display import \\\n",
    "    clear_output\n",
    "\n",
    "from raw import \\\n",
    "    get_plate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# String -> String\n",
    "def rename_column(col):\n",
    "    \"\"\" Rename column col to remove whitespace, backslashes, prefixes,\n",
    "        and suffixes (esp. large parenthetic suffix). \"\"\"\n",
    "    if col.startswith('Cell:'):\n",
    "        return col.split('(')[0].lstrip(\"Cell:\").rstrip('/').strip(' ')\n",
    "    else:\n",
    "        return col.split('(')[0].rstrip('/').strip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plate_import_config = dict(\n",
    "    delimiter = '\\t',\n",
    "    skiprows = 4,\n",
    "    dropcols = ['Laser focus score',\n",
    "                '\\.[0-9]*\\Z'],\n",
    "    colrename = rename_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract files into temporary working directory\n",
    "zipfile_path = '/notebooks/add-data/data.zip'\n",
    "extract_path = '/notebooks/tmp/extracted-data/'\n",
    "temp_save_path = '/notebooks/tmp/imported-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Series -> String\n",
    "def generate_cell_sid(cell_data):\n",
    "    \"\"\" Given Series containing cell information, \n",
    "        generate hash string to use as string id. \"\"\"\n",
    "    \n",
    "    # String -> String\n",
    "    def computeMD5hash(string):\n",
    "        m = hashlib.md5()\n",
    "        m.update(string.encode('utf-8'))\n",
    "        return m.hexdigest()\n",
    "    \n",
    "    columns_to_hash = \\\n",
    "        ['Plate ID',\n",
    "         'Well Name',\n",
    "         'Site ID',\n",
    "         'Cell ID']\n",
    "    \n",
    "    return thread_last(\n",
    "        cell_data[columns_to_hash].tolist(),\n",
    "        (map,str),\n",
    "        (str.join,' '),\n",
    "        computeMD5hash, \n",
    "        lambda string: 'CELL_' + string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Series -> DataFrame\n",
    "def gather_plate_data(plate_metadata):\n",
    "    \"\"\" Given Series containing filepaths for plate and layout,\n",
    "        import these files, join them, and add the series itself \n",
    "        to create a master table for all the info about the plate. \"\"\"\n",
    "    \n",
    "    # String -> String -> String\n",
    "    get_path = lambda directory, column: \\\n",
    "        os.path.join(\n",
    "            extract_path,\n",
    "            directory,\n",
    "            plate_metadata[column])\n",
    "        \n",
    "    plate_data = thread_last(\n",
    "        ['Plates','Plate File'],\n",
    "        (apply,get_path),\n",
    "        lambda path: get_plate_data(path,\n",
    "                                    plate_import_config))\n",
    "    \n",
    "    # Add string ID for use as primary key\n",
    "    plate_data['Cell SID'] = plate_data.apply(generate_cell_sid,\n",
    "                                              axis = 1)\n",
    "    \n",
    "    layout_data = thread_last(\n",
    "        ['Layouts','Layout File'],\n",
    "        (apply,get_path),\n",
    "        lambda path: get_layout_data(path))\n",
    "    \n",
    "    return thread_first(\n",
    "        pd.merge(plate_data,layout_data,on = 'Well Name'),\n",
    "        (add_dict_to_dataframe,dict(plate_metadata)),\n",
    "        (add_col,'Upload Timestamp',arrow.now().timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_message(tests):\n",
    "    \"\"\" Print out statements for all tests that fail. \"\"\"\n",
    "    return thread_last(\n",
    "        tests,\n",
    "        (partition,2),\n",
    "        (filter,lambda pair: pair[0] == False),\n",
    "        (map,snd),\n",
    "        (str.join,'\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check(_):\n",
    "    \"\"\" Extract zip and prepare for import into main dataset. \n",
    "        If data can be imported, then create a new csv in a temp directory. \n",
    "        Returns string of any warning or errors in this process. \"\"\"\n",
    "    \n",
    "    if os.path.exists(extract_path):\n",
    "        shutil.rmtree(extract_path) # clear out existing files\n",
    "\n",
    "    with zipfile.ZipFile(zipfile_path, \"r\") as z:\n",
    "        z.extractall(extract_path)    \n",
    "        \n",
    "    # Check files for correctness\n",
    "    exists = exists_at_path(extract_path) # curried function\n",
    "    nonempty = lambda entity: len(os.listdir(os.path.join(extract_path,entity))) > 0\n",
    "    initial_tests = \\\n",
    "        [exists('metadata.csv'), \"File missing: metadata.csv\",\n",
    "         exists('Plates/'), \"Folder missing: Plates\",\n",
    "         exists('Layouts/'), \"Folder missing: Layouts\",\n",
    "         nonempty('Plates/'), \"It looks like you haven't got any plates in your Plates folder.\",\n",
    "         nonempty('Layouts/'), \"It looks like you haven't got any layouts in your Layouts folder.\"]\n",
    "    \n",
    "    err = generate_message(initial_tests)\n",
    "    clear_output()\n",
    "    \n",
    "    if err != '':\n",
    "        print \"### ERROR ###\"\n",
    "        print err\n",
    "    else: \n",
    "        metadata_path = os.path.join(extract_path,'metadata.csv')\n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "        all_data = thread_last(\n",
    "            metadata,\n",
    "            (maprows,gather_plate_data),\n",
    "            pd.concat)\n",
    "        \n",
    "        if os.path.exists(temp_save_path):\n",
    "            shutil.rmtree(temp_save_path)\n",
    "        os.makedirs(temp_save_path)\n",
    "        all_data.to_csv(os.path.join(temp_save_path,'new_data.csv'),\n",
    "                        index=False)\n",
    "        print \"Ready to upload {} cells!\".format(format_num(len(all_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stage_button = widgets.Button(description = \"Check data\")\n",
    "stage_button.on_click(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to upload 139,070 cells!\n"
     ]
    }
   ],
   "source": [
    "stage_button"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
