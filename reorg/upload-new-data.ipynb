{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove unused functions from library / combine/separate libraries into better modules\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import arrow\n",
    "import pandas as pd\n",
    "import IPython.html.widgets as widgets\n",
    "\n",
    "from toolz import \\\n",
    "    partition,\\\n",
    "    thread_last,\\\n",
    "    thread_first\n",
    "    \n",
    "from utils import \\\n",
    "    snd,\\\n",
    "    exists_at_path,\\\n",
    "    get_layout_data,\\\n",
    "    add_dict_to_dataframe,\\\n",
    "    add_col\n",
    "    \n",
    "from IPython.display import \\\n",
    "    clear_output\n",
    "\n",
    "from raw import \\\n",
    "    get_plate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# String -> String\n",
    "def rename_column(col):\n",
    "    \"\"\" Rename column col to remove whitespace, backslashes, prefixes,\n",
    "        and suffixes (esp. large parenthetic suffix). \"\"\"\n",
    "    if col.startswith('Cell:'):\n",
    "        return col.split('(')[0].lstrip(\"Cell:\").rstrip('/').strip(' ')\n",
    "    else:\n",
    "        return col.split('(')[0].rstrip('/').strip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plate_config = dict(\n",
    "    delimiter = '\\t',\n",
    "    skiprows = 4,\n",
    "    dropcols = ['Laser focus score',\n",
    "                '\\.[0-9]*\\Z'],\n",
    "    normcols = [['Normalized_ColocSpot_area_sum (coloc)',\n",
    "                  ['ColocSpots_area_sum'],\n",
    "                  ['FITC-TxRed_coloc_area_sum']],\n",
    "                ['Normalized_ColocSpot_area_sum (all)',\n",
    "                  ['ColocSpots_area_sum'],\n",
    "                  ['FITC-TxRed_all_area_sum']],\n",
    "        \n",
    "                ['Normalized coloc spots (by FITC & TxRed)',\n",
    "                  ['# of Coloc Spots'],\n",
    "                  ['# of FITC spots', '# of TxRed spots']],\n",
    "                ['Normalized coloc spots (by FITC)',\n",
    "                  ['# of Coloc Spots'],\n",
    "                  ['# of FITC spots']],\n",
    "                ['Normalized coloc spots (by TxRed)',\n",
    "                  ['# of Coloc Spots'],\n",
    "                  ['# of TxRed spots']],\n",
    "               \n",
    "                ['Normalized coloc spots (by FITC in coloc)',\n",
    "                  ['# of Coloc Spots'],\n",
    "                  ['# of FITC in ColocSpots']],\n",
    "                ['Normalized coloc spots (by TxRed in coloc)',\n",
    "                  ['# of Coloc Spots'],\n",
    "                  ['# of TxRed in ColocSpots']],\n",
    "                ['Normalized coloc spots (by FITC-TxRed in coloc)',\n",
    "                  ['# of Coloc Spots'],\n",
    "                  ['# of FITC-TxRed in ColocSpots']]],\n",
    "    colrename = rename_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract files into temporary working directory\n",
    "zipfile_path = '/notebooks/add-data/data.zip'\n",
    "extract_path = '/notebooks/tmp/extracted-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_message(tests):\n",
    "    \"\"\" Print out statements for all tests that fail. \"\"\"\n",
    "    return thread_last(\n",
    "        tests,\n",
    "        (partition,2),\n",
    "        (filter,lambda pair: pair[0] == False),\n",
    "        (map,snd),\n",
    "        (str.join,'\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check(_):\n",
    "    \"\"\" Extract zip and prepare for import into main dataset. \n",
    "        If data can be imported, then create a new csv in a temp directory. \n",
    "        Returns string of any warning or errors in this process. \"\"\"\n",
    "    \n",
    "    shutil.rmtree(extract_path) # clear out existing files\n",
    "\n",
    "    with zipfile.ZipFile(zipfile_path, \"r\") as z:\n",
    "        z.extractall(extract_path)    \n",
    "        \n",
    "    # Check files for correctness\n",
    "    exists = exists_at_path(extract_path) # curried function\n",
    "    nonempty = lambda entity: len(os.listdir(os.path.join(extract_path,entity))) > 0\n",
    "    initial_tests = \\\n",
    "        [exists('metadata.csv'), \"File missing: metadata.csv\",\n",
    "         exists('Plates/'), \"Folder missing: Plates\",\n",
    "         exists('Layouts/'), \"Folder missing: Layouts\",\n",
    "         nonempty('Plates/'), \"It looks like you haven't got any plates in your Plates folder.\",\n",
    "         nonempty('Layouts/'), \"It looks like you haven't got any layouts in your Layouts folder.\"]\n",
    "    \n",
    "    err = generate_message(initial_tests)\n",
    "    clear_output()\n",
    "    if err != '':\n",
    "        print \"### ERROR ###\"\n",
    "        print err\n",
    "    else: \n",
    "        print \"Ready to upload!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stage_button = widgets.Button(description = \"Check data\")\n",
    "stage_button.on_click(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stage_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(extract_path,'metadata.csv')\n",
    "metadata = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plate File</th>\n",
       "      <th>Layout File</th>\n",
       "      <th>Assay</th>\n",
       "      <th>Image Collection Date</th>\n",
       "      <th>Investigator</th>\n",
       "      <th>Magnification</th>\n",
       "      <th>Image Analysis Recipe</th>\n",
       "      <th>Experiment Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APB HS JS 60X 07.22.2015 ML216 MMC HU TS.txt</td>\n",
       "      <td>layout.csv</td>\n",
       "      <td>APB</td>\n",
       "      <td>7/22/2015</td>\n",
       "      <td>HS JS</td>\n",
       "      <td>60</td>\n",
       "      <td>APB HS JS 60X 07.22.2015 ML216 MMC HU TS</td>\n",
       "      <td>APB/ssC Drug Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ssC HS JS 07.20.2015 ML216 MMC HU TS .txt</td>\n",
       "      <td>layout.csv</td>\n",
       "      <td>ssC</td>\n",
       "      <td>7/22/2015</td>\n",
       "      <td>HS JS</td>\n",
       "      <td>60</td>\n",
       "      <td>ssC HS JS 60X 07.22.2015 ML216 MMC HU TS</td>\n",
       "      <td>APB/ssC Drug Response</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Plate File Layout File Assay  \\\n",
       "0  APB HS JS 60X 07.22.2015 ML216 MMC HU TS.txt  layout.csv   APB   \n",
       "1     ssC HS JS 07.20.2015 ML216 MMC HU TS .txt  layout.csv   ssC   \n",
       "\n",
       "  Image Collection Date Investigator  Magnification  \\\n",
       "0             7/22/2015        HS JS             60   \n",
       "1             7/22/2015        HS JS             60   \n",
       "\n",
       "                      Image Analysis Recipe        Experiment Name  \n",
       "0  APB HS JS 60X 07.22.2015 ML216 MMC HU TS  APB/ssC Drug Response  \n",
       "1  ssC HS JS 60X 07.22.2015 ML216 MMC HU TS  APB/ssC Drug Response  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plate = metadata.iloc[0]\n",
    "\n",
    "plate_path = \\\n",
    "    os.path.join(\n",
    "        extract_path,\n",
    "        'Plates',\n",
    "        plate['Plate File'])\n",
    "\n",
    "layout_path = \\\n",
    "    os.path.join(\n",
    "        extract_path,\n",
    "        'Layouts',\n",
    "        plate['Layout File'])\n",
    "\n",
    "upload_timestamp = arrow.now().timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plate_data = get_plate_data(plate_path,plate_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layout_data = get_layout_data(layout_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data = thread_first(\n",
    "    pd.merge(plate_data,layout_data,on = 'Well Name'),\n",
    "    (add_dict_to_dataframe,dict(plate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Series -> DataFrame\n",
    "def gather_plate_data(plate_metadata):\n",
    "    \"\"\" Given Series containing filepaths for plate and layout,\n",
    "        import these files, join them, and add the series itself \n",
    "        to create a master table for all the info about the plate. \"\"\"\n",
    "    \n",
    "    get_path = lambda directory, column: \n",
    "        os.path.join(\n",
    "            extract_path,\n",
    "            directory,\n",
    "            plate_metadata[column])\n",
    "            \n",
    "    plate_path = get_path('Plates','Plate File')\n",
    "    layout_path = get_path('Layouts','Layout File')\n",
    "    \n",
    "    plate_data = get_plate_data(plate_path,plate_config)\n",
    "    layout_data = get_layout_data(layout_path)\n",
    "    \n",
    "    all_data = thread_first(\n",
    "        pd.merge(plate_data,layout_data,on = 'Well Name'),\n",
    "        (add_dict_to_dataframe,dict(plate)),\n",
    "        (add_col,'Upload Timestamp',arrow.now().timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
